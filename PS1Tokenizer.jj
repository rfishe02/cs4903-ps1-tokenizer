/**
 * JavaCC template file created by SF JavaCC plugin 1.5.28+ wizard for JavaCC 1.5.0+
 */options{  static = false;
  LOOKAHEAD=2;}PARSER_BEGIN(UATokenizer)
import java.io.IOException;
import java.io.FileReader;
import java.io.BufferedInputStream;
import java.io.FileInputStream;
import java.io.BufferedWriter;
import java.io.FileWriter;
import java.io.File;

public class UATokenizer{  public static void main(String args[]) throws ParseException  {

	test(args);
	//run(args);
      } 

  public static void test(String[] args) {

	args = new String[2];
    args[0] = "./input/test.txt";
    args[1] = "./output";

	//test.txt

	try {

		BufferedInputStream bis = new BufferedInputStream(new FileInputStream(args[0]));
		UATokenizer parser = new UATokenizer(bis);
		Token t;

		do {

			t = parser.getNextToken();

			if(!UATokenizer.tokenImage[t.kind].equals("<MISC>")) {
				System.out.printf("%20s %20s\n",t.image,UATokenizer.tokenImage[t.kind]);
			} else {
				//System.out.printf("%20s %20s\n",t.image,UATokenizer.tokenImage[t.kind]);
			}

		} while(t.kind != UATokenizerConstants.EOF);

	} catch(IOException ex) {
		System.exit(1);
	}

  }

  public static void run(String[] args) {

	String[] spl;
	String filename;

	try {

	  	File outDir = new File(args[1]);

	  	if(!outDir.exists()) {
			outDir.mkdir();
	  	}

		File inDir = new File(args[0]);
	  	File[] files = inDir.listFiles();

	  	for(File f : files) {

            BufferedWriter bw = new BufferedWriter(new FileWriter(args[1]+"/"+f.getName()+".out"));

			BufferedInputStream bis = new BufferedInputStream(new FileInputStream(f.getPath()));
			UATokenizer parser = new UATokenizer(bis);
			Token t;

			do {

				t = parser.getNextToken();

				if(!UATokenizer.tokenImage[t.kind].equals("<MISC>")) {
					bw.write(t.image.toLowerCase()+"\n");
				}

			} while(t.kind != UATokenizerConstants.EOF);

			bw.close();            

	  	}

	} catch(IOException ex) {
		System.exit(1);
	}

  }
  }PARSER_END(UATokenizer)

TOKEN_MGR_DECLS : {

	int tagSt;
	boolean tagCt;
	
}
SKIP : {  < SPACE : (" "|"\t"|"&nbsp;")+ >| < NEWLINE : ("\r"|"\n") >}

/*
	Random patterns of human constructs. Price is necessary, but I'm not sure how useful
	time and courses will be.
*/

SKIP : {
	< TIME : (["0"-"9"]){1,2}(":")( (["0"-"9"]){2}(":")? )+ (" ")? (["a"-"z","A"-"Z"]){0,2} >
}

TOKEN : {    
    < COURSE : (["A"-"Z"]){2,4} (" ")? (["0"-"9"]){4} >
| 	< PRICE : ["$","£","¥"](" ")*( (["0"-"9"]){1,3}(",")? )+ ( "."(["0"-"9"])+ )? > // Still need to consider more international options
}

/*
	Uses a grouping based approach to identify phone numbers. The most popular numbers internationally followed
	groupings of 3-3-3, 3-3-4, 3-2-2, 2-2-2, or 5-8, which were preceded by some codes.

	Also provides a distinction between IP Addresses and phone numbers, or certain numbers.
*/

TOKEN : {
    < IP : ( ( "2"(["0"-"5"]){2}| "1"(["0"-"9"]){2}|(["0"-"9"]){1,2} ) ){1} ( ["."]( "2"(["0"-"5"]){2}| "1"(["0"-"9"]){2}|(["0"-"9"]){1,2})){3} ("/" ( ("08"){1}| "16" | "2"(["4"-"9"]){1}|"32"))? >
| 	< PHONE34 : (  ( ("+")?("(")?(["0"-"9"]){1,3}(")")?["-"," ","."] )?  ("(")?(["0"-"9"]){1,4}(")")?["-"," ","."]  )?
		(["0"-"9"]){3,4}(["-"," ","."])(["0"-"9"]){3,4}
	>
| 	< PHONE32 : (  ( ("+")?("(")?(["0"-"9"]){1,4}(")")?["-"," ","."] )?  ("(")?(["0"-"9"]){2,4}(")")?["-"," ","."]  )?
		(["0"-"9"]){2,3}["-"," ","."]  (["0"-"9"]){2}["-"," ","."](["0"-"9"]){2}
	>
|   < PHONE35 : (  ("+")?(["0"-"9"]){1,2}["-"," ","."]  )?
		("(")?(["0"-"9"]){2,5}(")")?["-"," ","."]  (["0"-"9"]){5,8}
	>
}

/*
	These two MORE sections attempt to grab combined words/ tricky numbers.
	(Contractions, formatted numbers, or odd puntuation).

	It may pass through MORE once, or twice in TAGINT, where the token is modified.
	Eventually, it's classified as WORD or NUMBER when it reaches the following
	regex expressions.

	I *may* use this to deal with w o r d s l i k e t h e s e.
*/

TOKEN : {
    < CROWDED1 : ">" ((["a"-"z","A"-"Z"])+|< REDDITU >) > {
		matchedToken.image = image.substring(image.indexOf(">")+1,image.length());
    }
}

MORE :
{
  	< TAGINT :  (["a"-"z","A"-"Z"])+ ("<" ("/")? (["a"-"z","0"-"9"])+ ">" ) > {

		if(!tagCt) {
	  		tagCt = true;
	  	}
		image.delete(image.indexOf("<"),image.length()); // Probably not efficient.
  		
  	}
|   < CONT : (["a"-"z","A"-"Z"])+"'" >
| 	< TECH : (["a"-"z","A"-"Z"])+(["0"-"9"])+ >
| 	< BIGNUM : (["0"-"9"])+(","|".") >
}

/* The two TOKEN below grab basic / complex words that don't require the
   concatentation of the preceding MORE sections.
 */

TOKEN : {
 	< BREV : (["A"-"Z"]"."(" ")?)+ >
|   < REDDITU :  ["a"-"z"] (["/"]) (["a"-"z","A"-"Z"])+ > // Specifically for reddit, a popular platform. May need to revisit this.
|	< USER : "@" (["a"-"z","A"-"Z"])+ >
}

TOKEN : {
  	< WORD : (["a"-"z","A"-"Z"])+ > {
  
  	  if(tagCt) {
		matchedToken.image = image.toString(); // If this word had odd punctuation, set the modfied image.
		tagCt = false;
	  }
	  
  	}
| 	< NUMBER : (["0"-"9"])+>
| 	< MISC: ~[] >
}

/*
	The follwoing attempt to skip tags and certain attributes, such as style and
	script tags that do not contribute useful information.
	
	Alse tries to exclude href, src, and alt attributes from omission. These terms
	are picked up by other regex expressions.
*/

SKIP : {
	< SPTAG : "<" (" ")*("style"|"script"|"button"|"noscript")(" ")* > : IN_SK_TAG
|   < OPENTAG : "<" (" ")*(["a"-"z","A"-"Z","0"-"9"])+(" ")* >
|   < CLOSETAG : "<" (" ")*"/"(" ")* (["a"-"z","A"-"Z","0"-"9"])+ (" ")* ">" >
|   < SPATTR :  ("href"|"src"|"alt") (" ")*"="(" ")* "\"" >
|   < HTMLATTR : (["a"-"z","A"-"Z","-"])+ (" ")*"="(" ")* "\"" > : IN_SK_ATTR
}

< IN_SK_TAG > SKIP : {
	< ENDATAG : "<" (" ")*"/"(" ")* "style" > : DEFAULT
| 	< ENDBTAG : "<" (" ")*"/"(" ")* "script" > : DEFAULT
| 	< ENDCTAG : "<" (" ")*"/"(" ")* "button" > : DEFAULT
| 	< ENDDTAG : "<" (" ")*"/"(" ")* "noscript" > : DEFAULT
|   < SPTAGMISC : ~[] >
}

< IN_SK_ATTR > SKIP : {
	< ENDSPATTR : ("\""|">") > : DEFAULT
|   < SPATTRMISC : ~[] >
}

/*
	Skip parts of the url that may contribute more garbage than relevant information.
	(I am 60% certain that this information isn't useful).
*/

SKIP : {
 	< HTTPJNK : ("&"|"?"|"%") (["a"-"z","A"-"Z","0"-"9",".","-","_","=",";",":","+"])+ >
| 	< HTTPLNK : ("/") (["a"-"z","A"-"Z","0"-"9",".","-","_","=",";",":","+"])+ >
|   < HTTP : (["a"-"z"])+("://")+ >
| 	< PORT : ":"(["0"-"9"]){2,4} >
}

/*
	Only retain HTML domains, parts of the url, email addresses that seem useful.
*/

TOKEN : {	
    < HTTPDOM : ( (["a"-"z","A"-"Z"]){1}(["a"-"z","A"-"Z"])+(".") )+ (["a"-"z","A"-"Z"])+ >
|   < EMAIL : (["a"-"z","A"-"Z","0"-"9","_",".","+","-"])+ "@" ((["a"-"z","A"-"Z"])+(".")?)+ > // Fix, because it can't start or end with certain things?
}

/*-------------------------------*/
/* Tried, but unhelpful. Yet, I can't delete them.

|   < PRICE1 : ["$","£","¥"](["0"-"9"]){1,3}(","|".") > : PRICE_STATE

< PRICE_STATE > MORE :
{
	< PRICE2 : (["0"-"9"]){1,3}(","|".") >
}

< PRICE_STATE > TOKEN :
{
 	< PRICE : (["0"-"9"])+ > : DEFAULT
| 	< MISC2: ~[] > : DEFAULT 
}


|   < FLAG : (["a"-"z","A"-"Z"])+ ["<","/",">"] > { image.deleteCharAt(image.length()-1); System.out.println(image); } // Need to figure this out.


 ( (" ")*((["a"-"z","A"-"Z","0"-"9","-","=",";","[","]","_"])+(" ")*)+ )? "\""


< OBS : (["a"-"z","A"-"Z"])+ (["<"]) > 
  	{

	  System.out.println("\n"+image+"\n");
  	  
      if(!tagCt) {
	  	tagCt = true;
	  }
  	  tagSt = image.length()-1;

  	} : OBS_PARSE
|

< OBS_PARSE > MORE : {
	< A : ">" > {
      image.delete(tagSt,image.length()); // Create a truncated word, without offending punctuation.
	  } : DEFAULT
| 	< C : ~[] > 
}

-------------------------------*/
/**
 * JavaCC template file created by SF JavaCC plugin 1.5.28+ wizard for JavaCC 1.5.0+
 */
options
{
  static = false;
  LOOKAHEAD=1;
}

PARSER_BEGIN(UATokenizer)

import java.io.IOException;
import java.io.FileReader;
import java.io.BufferedInputStream;
import java.io.BufferedReader;
import java.io.FileInputStream;
import java.io.BufferedWriter;
import java.io.FileWriter;
import java.io.File;
import java.io.InputStreamReader;

public class UATokenizer
{

  static boolean test = false;
  
  public static void main(String args[]) throws ParseException
  {

    if(test) {
		args = new String[2];
    	args[0] = "./input/test.txt";
    	args[1] = "./output";
    }

	run(args);
    
  }

  public static void run(String[] args) {

    File[] files;
    File[] zDir;
    File inDir;
	String[] spl;
	String filename;
	int[] count = new int[7];
	long start;

	try {

	  	inDir = new File(args[0]);
	  	files = inDir.listFiles();

		File outDir = new File(args[1]);
		if(!outDir.exists()) {
			outDir.mkdir();
	  	}
	  	
		BufferedWriter[] bw = getWriters(outDir);
		start = System.currentTimeMillis();

	  	if(files == null) {
	  	 	processFile(bw,inDir,count); // Process a single file.
			
	  	} else {
	  	  
			for(File f : files) {
            	
                zDir = f.listFiles();
                
                if(zDir != null) {
                    
                    for(File z : zDir) {
                        processFile(bw,z,count); // Process a file in a subdirectory.
                    }
                    
                } else {
                    processFile(bw,f,count); // Process multiple files.
                }
                
	  		}
	  		
	  	}

		closeWriters(bw);
	  	printResults(count,start);
		
	} catch(IOException ex) {
	  	ex.printStackTrace();
		System.exit(1);
	}

  }

  public static void processFile(BufferedWriter[] bw, File f, int[] count) throws IOException {

	BufferedReader bis;
	UATokenizer parser;
	Token t;

	bis = new BufferedReader(new InputStreamReader(new FileInputStream(f),"UTF-8"));
    parser = new UATokenizer(bis);
		
	do {
		t = parser.getNextToken();
		recordToken(bw,t,count);

	} while(t.kind != UATokenizerConstants.EOF);

	bis.close();
	count[1]++;

  }
  
  public static BufferedWriter[] getWriters(File inDir) {

	BufferedWriter[] bw = null;

	try {

		String[] filenames = {"other.txt","email.txt","domain.txt","price.txt","word.txt","phone.txt"};
		bw = new BufferedWriter[filenames.length];

		for (int i = 0; i < filenames.length; i++) {
		  	bw[i] = new BufferedWriter(new FileWriter(inDir.getPath()+"/"+filenames[i]));
		}

	} catch(IOException ex) {
	  	ex.printStackTrace();
		System.exit(1);
	}

	return bw;
	
  }

  public static void closeWriters(BufferedWriter[] bw) {

	try {
		for(BufferedWriter b : bw) {
	  		b.close();
		}
	} catch(IOException ex) {
		System.exit(1);
	}
	
  }

  public static void recordToken(BufferedWriter[] bw, Token t, int[] count) {

	//"tokens.txt","email.txt","domain.txt","price.txt","word.txt","phone.txt"
	//"total","files","email","domain","price","word","phone"

	try {

	  String type = UATokenizer.tokenImage[t.kind];
	  String fmt = t.image.toLowerCase();

	  count[0]++; // Count number of tokens processed.
	
	  if(type.equals("<EMAIL>")) {
		bw[1].write(fmt+"\n");
		count[2]++;
		
	  } else if(type.equals("<HTTPDOM>")) {
		bw[2].write(fmt+"\n");
		count[3]++;

	  } else if(type.equals("<PRICE>")) {
		bw[3].write(fmt+"\n");
		count[4]++;
		
	  } else if(type.equals("<PHONE34>")|| type.equals("<PHONE32>")|| type.equals("<PHONE58>")) {
		bw[5].write(fmt+"\n");
		count[6]++;
		
	  } else if(!type.equals("<BIGNUM>")) {
		bw[4].write(fmt+"\n");
		count[5]++;
	  } else {
		bw[0].write(fmt+"\n"); // Write remaining tokens to a separate file.
	  }

	} catch(IOException ex) {
		System.exit(1);
	}

  }

  public static void printResults(int[] count, long start) {

	try {
        
        BufferedWriter bw = new BufferedWriter(new FileWriter("summary.txt"));
     
        String[] label = {"Total tokens: ","Files processed: ","Emails found: ","Domains found: ","Prices found: ","Words found: ","Phone #s found:"};

        bw.write("======= Project Gengar Tokenization Summary =======\n");
        
        for(int i = 0; i < label.length; i++) {
			//System.out.printf("%-25s %-50d\n",label[i],count[i]);
            bw.write(String.format("%-25s %-50d\n",label[i],count[i]));
        }
        
        //System.out.printf("%-25s %-50.2f","Total runtime (seconds): ",(System.currentTimeMillis()-start)/1000.0);
        bw.write(String.format("%-25s %-50.2f\n","Total runtime (seconds): ",(System.currentTimeMillis()-start)/1000.0));
        
        bw.close();
        
    } catch(IOException ex) {
        System.exit(1);
    }

  }
  
}

PARSER_END(UATokenizer)

TOKEN_MGR_DECLS : {

	int wordEnd;
	int tagSt;
	boolean tagCt;
	boolean cont;

	String aps = "('|’|\u2019|&#39;|&#44;|&#x27;|-|&#45;)";
	String psep = "([\\(]|[\\)]|[+]|&#43;|&#45;|&#46;)";
    
    	String[] tmp;
	
}

SKIP : {
  < SPACE : (" "|"\t")+ >
| < NEWLINE : ("\r"|"\n")+ >
| < APS : ("'"|"’"|"\u2019"|"&#39;"|"&#44;"|"â€™"|"&#x27;") >
| < PSEP : (["-"," ","."]|"&#45;"|"&#46;") > // Phone seperator.
}

/*
    Attempt to skip tags that do not contribute useful information.
*/

SKIP : {
    < SCRIPTTAG :  "<" (" ")*"script"(" ")* > : IN_SCRIPT_TAG
|   < SPTAG : "<" (" ")*("style"|"button"|"noscript"|"!--")(" ")* > : IN_SP_TAG
|   < SELFCLOSETAG : "<" (" ")*("link"|"meta"|"i")(" ")* > : IN_SELFCLOSE_TAG
|   < PHP : "<" (" ")*"?php"(" ")* > : IN_PHP
|   < OPENTAG : "<" (" ")*(["a"-"z","A"-"Z","0"-"9","-"])+(" ")* >
|   < CLOSETAG : "<" (" ")*( "/"(" ")*(["a"-"z","A"-"Z","0"-"9","-"])+ | (["a"-"z","A"-"Z","0"-"9","-"])+(" ")*"/" )(" ")* >
}

< IN_SCRIPT_TAG > SKIP : {
   < ENDSCRIPTTAG : "<" (" ")*"/"(" ")* "script" > : DEFAULT
|  < SCRIPTTAGMISC : ~[] > 
}

< IN_SP_TAG > SKIP : {
    < ENDATAG : "<" (" ")*"/"(" ")* "style" > : DEFAULT
|   < ENDCTAG : "<" (" ")*"/"(" ")* "button" > : DEFAULT
|   < ENDDTAG : "<" (" ")*"/"(" ")* "noscript" > : DEFAULT
|   < ENDCMT : "-->" > : DEFAULT
|   < SPTAGMISC : ~[] >
}

< IN_SELFCLOSE_TAG > SKIP : {
    < ENDOPTAG : (">") > : DEFAULT
|   < SELFCLOSEMISC : ~[] >
}

< IN_PHP > SKIP : {
    < ENDPHP : "?>" > : DEFAULT
|   < PHPMISC : ~[] >
}

/*
    Attempt to skip attributes that do not contribute useful information.
    
    < FILE2 : "./" (["a"-"z","A"-"Z","0"-"9",".","-","_","=",";",":","+"," "])+ >
*/

SKIP : {
    < SPATTR :  ("alt") (" ")*"="(" ")* ("\""|"'") >
|   < SPATTRLNK :  "href" (" ")*"="(" ")* ("\""|"'") > : IN_SPATTR_LNK
|   < HTMLATTRDQ : (["a"-"z","A"-"Z","-","_"])+ (" ")*"="(" ")* "\"" > : IN_HTMLATTR_DQ
|   < HTMLATTRSQ : (["a"-"z","A"-"Z","-","_"])+ (" ")*"="(" ")* "'" > : IN_HTMLATTR_SQ
|   < SYMBOL : (["a"-"z","A"-"Z"])? "&"("#")? (["a"-"z","A"-"Z","0"-"9"]){2,4}";" > 
}

<IN_SPATTR_LNK> SKIP : {
    < HTTPLNK2 : ("/"|"./") (["a"-"z","A"-"Z","0"-"9",".","-","_","=",";",":","+","?","%","&"])+ >
|   < HTTP2 : ((["a"-"z"])+|("chrome-extension")) ("://")+ >
|   < PORT2 : ":"(["0"-"9"]){2,4} >
|   < SPATTRMISC: ~[] >
}

<IN_SPATTR_LNK> TOKEN : {
    < HTTPDOM2 : ( (["a"-"z","A"-"Z","0"-"9"]){1}(["a"-"z","A"-"Z","0"-"9"])+(".") )+ (["a"-"z","A"-"Z","0"-"9"])+ > {
        
        tmp = image.toString().split("\\.");
        matchedToken.image = tmp[tmp.length-2]+"."+tmp[tmp.length-1];
        
    } : DEFAULT
}

< IN_HTMLATTR_DQ > SKIP : {
    < ENDSPATTR : ("\""|">") > : DEFAULT
|   < HTMLATTRMISC1 : ~[] >
}

< IN_HTMLATTR_SQ > SKIP : {
    < ENDSPATTR2 : ("'"|">") > : DEFAULT
|   < HTMLATTRMISC2 : ~[] >
}

/*
	Random patterns of human constructs. Price is necessary, but I'm not sure how useful
	time and courses will be.
	
	removed 6-13-19
	SKIP : {
		< TIME : (["0"-"9"]){1,2}(":")( (["0"-"9"]){2}(":"|"&#58;")? )+ (" ")? (["a"-"z","A"-"Z"]){0,2} >
	}
	
*/

TOKEN : {
    < ERA : (["0"-"9"]){2,4}< APS >"s" > { matchedToken.image = matchedToken.image.replaceAll(aps,""); }
|   < COURSE : (["A"-"Z"]){2,4} (" ")? (["0"-"9"]){4} > { matchedToken.image = matchedToken.image.replaceAll(" ",""); }
|   < PRICE : ["$","£","¥"](" ")*( (["0"-"9"]){1,3}(",")? )+ ( "."(["0"-"9"])+ )? > // Need to add unicode & html symb?
}

/*
	Uses a grouping based approach to identify phone numbers. The most popular numbers internationally followed
	groupings of 3-3-3, 3-3-4, 3-2-2, 2-2-2, or 5-8, which were preceded by some codes.

	Also provides a distinction between IP Addresses and phone numbers, or certain numbers.
*/

SKIP : {
    < IP : ( ( "2"(["0"-"5"]){2}| "1"(["0"-"9"]){2}|(["0"-"9"]){1,2} ) ){1} ( ["."]( "2"(["0"-"5"]){2}| "1"(["0"-"9"]){2}|(["0"-"9"]){1,2})){3} ("/" ( ("08"){1}| "16" | "2"(["4"-"9"]){1}|"32"))? >
}

TOKEN : {
 	< PHONE34 : (  ( ("+"|"&#43;")?("(")?(["0"-"9"]){1,3}(")")?< PSEP > )?  ("(")?(["0"-"9"]){1,4}(")")?< PSEP >  )?
		(["0"-"9"]){3,4}< PSEP >(["0"-"9"]){3,4}
	> { 
		tmp = image.toString().replaceAll(psep,"").split("[\\s,\\.,-]");
		if(tmp.length > 1) {
            matchedToken.image = tmp[tmp.length-2] + tmp[tmp.length-1];
        }
	}
| 	< PHONE32 : (  ( ("+"|"&#43;")?("(")?(["0"-"9"]){1,4}(")")?< PSEP > )?  ("(")?(["0"-"9"]){2,4}(")")?< PSEP >  )?
		(["0"-"9"]){2,3}< PSEP >  (["0"-"9"]){2}< PSEP >(["0"-"9"]){2}
	> { 
		tmp = image.toString().replaceAll(psep,"").split("[\\s,\\.,-]");
		if(tmp.length > 2) {
            matchedToken.image = tmp[tmp.length-3] + tmp[tmp.length-2] + tmp[tmp.length-1];
        }
	 }
|   < PHONE58 : (  ("+"|"&#43;")?(["0"-"9"]){1,2}< PSEP >  )?
		("(")?(["0"-"9"]){2,5}(")")?< PSEP >(["0"-"9"]){5,8}
	> { 
		tmp = image.toString().replaceAll(psep,"").split("[\\s,\\.,-]");
		if(tmp.length > 1) {
            matchedToken.image = tmp[tmp.length-2] + tmp[tmp.length-1];
        }
	 }
}

/*
	The following sections attempt to grab combined words/ tricky numbers.
	(Contractions, formatted numbers, or odd puntuation).

	It may pass through MORE once, or twice.
	Eventually, it's classified as WORD or NUMBER when it reaches the
	following regex expressions.

	I *may* use this to deal with w o r d s l i k e t h e s e.
*/

MORE :
	{
    < CONT : (["a"-"z","A"-"Z"])+ (< APS >|"-") > {
	  cont = true;
    }
| 	< BIGNUM : (["0"-"9"])+(","|"&#44;"|"."|"&#46;") >
}

/* Deal with situations where terms are too close to tags.*/

TOKEN : {
    < CROWDED : ">" ( (< CONT >)?(["a"-"z","A"-"Z"])+) > {
      	matchedToken.image = image.substring(image.indexOf(">")+1,image.length());
		matchedToken.image = matchedToken.image.replaceAll(aps,"");
		
    }
|   < CROWDED2 : ( (< CONT >)?(["a"-"z","A"-"Z"])+) < CLOSETAG > > {
  		matchedToken.image = image.substring(0,image.indexOf("<"));
		matchedToken.image = matchedToken.image.replaceAll(aps,"");
  		
    }
}

/* 
	The next two tags are used to identify basic words / numbers.

	removed 6-14-19
	< BREV : (["A"-"Z"]("."|"&#46;")(" ")?)+ > {
  		matchedToken.image = matchedToken.image.replaceAll("\\.","").trim();
  	}
	< TECH : ((["a"-"z","A"-"Z"])+(["0"-"9"])*){2,6} >
*/

TOKEN : {
  	< WORD : (["a"-"z","A"-"Z"])+ > {

	  if(tagCt) {
  	    matchedToken.image = image.toString(); // If this word had odd punctuation, return the modfied image.
		tagCt = false;
	  }
	  if(cont) {
	    matchedToken.image = image.toString().replaceAll(aps,"");
		cont=false;
	  }
	  
  	}
}

SKIP : {
   	< NUMBER : (["0"-"9"])+>
| 	< MISC: ~[] >
}

/*
	Skip parts of the url that may contribute more garbage than relevant information.
	
	removed 6-14-19
 	< HTTPJNK : ("&"|"?"|"%") (["a"-"z","A"-"Z","0"-"9",".","-","_","=",";",":","+"])+ >
*/

SKIP : {
    < HTTPLNK : "/" (["a"-"z","A"-"Z","0"-"9",".","-","_","=",";",":","+","?","%","&"])+ >
|   < FILE : "./" (["a"-"z","A"-"Z","0"-"9",".","-","_","=",";",":","+"," "])+ >
|   < HTTP : ((["a"-"z"])+|("chrome-extension")) ("://")+ >
|   < PORT : ":"(["0"-"9"]){2,4} >
}

/*
	Only retain HTML domains, parts of the url, email addresses that seem useful.
*/

TOKEN : {	
    < HTTPDOM : ( (["a"-"z","A"-"Z"]){1}(["a"-"z","A"-"Z"])+(".") )+ (["a"-"z","A"-"Z"])+ > {
        
        tmp = image.toString().split("\\.");
        matchedToken.image = tmp[tmp.length-2]+"."+tmp[tmp.length-1];
        
    }
|   < EMAIL : (["a"-"z","A"-"Z","0"-"9","_",".","+","-","=","#","$","%","&","!","*","?"])+ "@" ((["a"-"z","A"-"Z"])+(".")?)+ > // Fix, because it can't start or end with certain things?
}


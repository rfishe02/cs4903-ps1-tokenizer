/**
 * JavaCC template file created by SF JavaCC plugin 1.5.28+ wizard for JavaCC 1.5.0+
 */
options
{
  static = false;
  LOOKAHEAD=1;
}

PARSER_BEGIN(UATokenizer)

import java.io.IOException;
import java.io.FileReader;
import java.io.BufferedInputStream;
import java.io.BufferedReader;
import java.io.FileInputStream;
import java.io.BufferedWriter;
import java.io.FileWriter;
import java.io.File;
import java.io.InputStreamReader;

public class UATokenizer
{

  static boolean test = false;
  
  public static void main(String args[]) throws ParseException
  {

    if(test) {
		args = new String[2];
    	args[0] = "./input/test.txt";
    	args[1] = "./output";
    }

	run(args);
    
  }

  public static void run(String[] args) {

    File[] files;
    File[] zDir;
    File inDir;
	String[] spl;
	String filename;
	int[] count = new int[7];
	long start;

	try {

	  	inDir = new File(args[0]);
	  	files = inDir.listFiles();

		File outDir = new File(args[1]);
		if(!outDir.exists()) {
			outDir.mkdir();
	  	}
	  	
		BufferedWriter[] bw = getWriters(outDir);
		start = System.currentTimeMillis();

	  	if(files == null) {
	  	 	processFile(bw,inDir,count); // Process a single file.
			
	  	} else {
	  	  
			for(File f : files) {
            	
                zDir = f.listFiles();
                
                if(zDir != null) {
                    
                    for(File z : zDir) {
                        processFile(bw,z,count); // Process a file in a subdirectory.
                    }
                    
                } else {
                    processFile(bw,f,count); // Process multiple files.
                }
                
	  		}
	  		
	  	}

		closeWriters(bw);
	  	printResults(count,start);
		
	} catch(IOException ex) {
	  	ex.printStackTrace();
		System.exit(1);
	}

  }

  public static void processFile(BufferedWriter[] bw, File f, int[] count) throws IOException {

	BufferedReader bis;
	UATokenizer parser;
	Token t;

	bis = new BufferedReader(new InputStreamReader(new FileInputStream(f),"UTF-8"));
    parser = new UATokenizer(bis);
		
	do {
		t = parser.getNextToken();
		recordToken(bw,t,count);

	} while(t.kind != UATokenizerConstants.EOF);

	bis.close();
	count[1]++;

  }
  
  public static BufferedWriter[] getWriters(File inDir) {

	BufferedWriter[] bw = null;

	try {

		String[] filenames = {"other.txt","email.txt","domain.txt","price.txt","word.txt","phone.txt"};
		bw = new BufferedWriter[filenames.length];

		for (int i = 0; i < filenames.length; i++) {
		  	bw[i] = new BufferedWriter(new FileWriter(inDir.getPath()+"/"+filenames[i]));
		}

	} catch(IOException ex) {
	  	ex.printStackTrace();
		System.exit(1);
	}

	return bw;
	
  }

  public static void closeWriters(BufferedWriter[] bw) {

	try {
		for(BufferedWriter b : bw) {
	  		b.close();
		}
	} catch(IOException ex) {
		System.exit(1);
	}
	
  }

  public static void recordToken(BufferedWriter[] bw, Token t, int[] count) {

	//"tokens.txt","email.txt","domain.txt","price.txt","word.txt","phone.txt"
	//"total","files","email","domain","price","word","phone"

	try {

	  String type = UATokenizer.tokenImage[t.kind];
	  String fmt = t.image.toLowerCase();

	  count[0]++; // Count number of tokens processed.
	
	  if(type.equals("<EMAIL>")) {
		bw[1].write(fmt+"\n");
		count[2]++;
		
	  } else if(type.equals("<HTTPDOM>")) {
		bw[2].write(fmt+"\n");
		count[3]++;

	  } else if(type.equals("<PRICE>")) {
		bw[3].write(fmt+"\n");
		count[4]++;
		
	  } else if(type.equals("<PHONE34>")|| type.equals("<PHONE32>")|| type.equals("<PHONE58>")) {
		bw[5].write(fmt+"\n");
		count[6]++;
		
	  } else if(!type.equals("<BIGNUM>")) {
		bw[4].write(fmt+"\n");
		count[5]++;
	  } else {
		bw[0].write(fmt+"\n"); // Write remaining tokens to a separate file.
	  }

	} catch(IOException ex) {
		System.exit(1);
	}

  }

  public static void printResults(int[] count, long start) {

	try {
        
        BufferedWriter bw = new BufferedWriter(new FileWriter("summary.txt"));
     
        String[] label = {"Total tokens: ","Files processed: ","Emails found: ","Domains found: ","Prices found: ","Words found: ","Phone #s found:"};

        bw.write("======= Project Gengar Tokenization Summary =======\n");
        
        for(int i = 0; i < label.length; i++) {
			//System.out.printf("%-25s %-50d\n",label[i],count[i]);
            bw.write(String.format("%-25s %-50d\n",label[i],count[i]));
        }
        
        //System.out.printf("%-25s %-50.2f","Total runtime (seconds): ",(System.currentTimeMillis()-start)/1000.0);
        bw.write(String.format("%-25s %-50.2f\n","Total runtime (seconds): ",(System.currentTimeMillis()-start)/1000.0));
        
        bw.close();
        
    } catch(IOException ex) {
        System.exit(1);
    }

  }
  
}

PARSER_END(UATokenizer)

TOKEN_MGR_DECLS : {

	int wordEnd;
	int tagSt;
	boolean tagCt;
	boolean cont;

	String aps = "('|’|\u2019|&#39;|&#44;|&#x27;|-|&#45;)";
	String psep = "([\\(]|[\\)]|[+]|&#43;|&#45;|&#46;)";
    
    String[] tmp;
	
}

SKIP : {
  < SPACE : (" "|"\t")+ >
| < NEWLINE : ("\r"|"\n") >
}

SKIP : {
  < APS : ("'"|"’"|"\u2019"|"&#39;"|"&#44;"|"â€™"|"&#x27;") >
| < PSEP : (["-"," ","."]|"&#45;"|"&#46;") > // Phone seperator.
}

/*
	The follwoing attempt to skip tags and certain attributes, such as style and
	script tags that do not contribute useful information.
	
	Alse tries to exclude href and alt attributes from omission. These attributes
	are picked up by other regex expressions.
*/

SKIP : {
    < OCTAG : "<" (" ")*("style"|"script"|"button"|"noscript"|"!--")" ")* > : IN_OC_TAG
|   < OPTAG : "<" (" ")*("link"|"meta"|"i")(" ")* > : IN_OP_TAG
|   < PHP : "<" (" ")*"?"(" ")*"php"(" ")* > : IN_PHP
|   < OPENTAG : "<" (" ")*(["a"-"z","A"-"Z","-"])+(["0"-"9"])?(" ")* >
|   < CLOSETAG : "<" (" ")*"/"(" ")*(["a"-"z","A"-"Z","-"])+(["0"-"9"])?(" ")* >
|   < HTMLATTR : (["a"-"z","A"-"Z","-","_"])+ (" ")*"="(" ")* "\"" > : IN_HTML_ATTR_DQ
|   < HTMLATTR2 : (["a"-"z","A"-"Z","-","_"])+ (" ")*"="(" ")* "'" > : IN_HTML_ATTR_SQ
}

/* removed 6-13-19
|   < SPATTR :  ("href"|"alt") (" ")*"="(" ")* ("\""|"'") >
|   < SYMBOL : "&"("#")?(["a"-"z","A"-"Z","0"-"9"]){2,4}";" > 
 */

< IN_OC_TAG > SKIP : {
	< ENDATAG : "<" (" ")*"/"(" ")* ("style") > : DEFAULT
| 	< ENDBTAG : "<" (" ")*"/"(" ")* ("script") > : DEFAULT
| 	< ENDCTAG : "<" (" ")*"/"(" ")* ("button") > : DEFAULT
| 	< ENDDTAG : "<" (" ")*"/"(" ")* ("noscript") > : DEFAULT
| 	< ENDCMT : "--"(" ")*">" > : DEFAULT
|   < SPTAGMISC : ~[] >
}

< IN_OP_TAG > SKIP : {
  	< ENDOPTAG : (">") > : DEFAULT
|   < OPTAGMISC : ~[] >
}

< IN_PHP > SKIP : {
	< ENDPHP : "?"(" ")*">" > : DEFAULT
}

< IN_HTML_ATTR_DQ > SKIP : {
	< ENDSPATTR : ("\""|">") > : DEFAULT
|   < SPATTRMISC : ~[] >
}

< IN_HTML_ATTR_SQ > SKIP : {
	< ENDSPATTR2 : ("'"|">") > : DEFAULT
|   < SPATTRMISC2 : ~[] >
}

/*
	Random patterns of human constructs. Price is necessary, but I'm not sure how useful
	time and courses will be.
*/

/* removed 6-13-19
SKIP : {
	< TIME : (["0"-"9"]){1,2}(":")( (["0"-"9"]){2}(":"|"&#58;")? )+ (" ")? (["a"-"z","A"-"Z"]){0,2} >
}*/

TOKEN : {
    < ERA : (["0"-"9"]){2,4}< APS >"s" > { matchedToken.image = matchedToken.image.replaceAll(aps,""); }
|   < COURSE : (["A"-"Z"]){2,4} (" ")? (["0"-"9"]){4} > { matchedToken.image = matchedToken.image.replaceAll(" ",""); }
| 	< PRICE : ["$","£","¥"](" ")*( (["0"-"9"]){1,3}(",")? )+ ( "."(["0"-"9"])+ )? > // Need to add unicode & html symb?
}

/*
	Uses a grouping based approach to identify phone numbers. The most popular numbers internationally followed
	groupings of 3-3-3, 3-3-4, 3-2-2, 2-2-2, or 5-8, which were preceded by some codes.

	Also provides a distinction between IP Addresses and phone numbers, or certain numbers.
*/

SKIP : {
    < IP : ( ( "2"(["0"-"5"]){2}| "1"(["0"-"9"]){2}|(["0"-"9"]){1,2} ) ){1} ( ["."]( "2"(["0"-"5"]){2}| "1"(["0"-"9"]){2}|(["0"-"9"]){1,2})){3} ("/" ( ("08"){1}| "16" | "2"(["4"-"9"]){1}|"32"))? >
}

TOKEN : {
 	< PHONE34 : (  ( ("+"|"&#43;")?("(")?(["0"-"9"]){1,3}(")")?< PSEP > )?  ("(")?(["0"-"9"]){1,4}(")")?< PSEP >  )?
		(["0"-"9"]){3,4}< PSEP >(["0"-"9"]){3,4}
	> { 
		tmp = image.toString().replaceAll(psep,"").split("[\\s,\\.,-]");
		if(tmp.length > 1) {
            matchedToken.image = tmp[tmp.length-2] + tmp[tmp.length-1];
        }
	}
| 	< PHONE32 : (  ( ("+"|"&#43;")?("(")?(["0"-"9"]){1,4}(")")?< PSEP > )?  ("(")?(["0"-"9"]){2,4}(")")?< PSEP >  )?
		(["0"-"9"]){2,3}< PSEP >  (["0"-"9"]){2}< PSEP >(["0"-"9"]){2}
	> { 
		tmp = image.toString().replaceAll(psep,"").split("[\\s,\\.,-]");
		if(tmp.length > 2) {
            matchedToken.image = tmp[tmp.length-3] + tmp[tmp.length-2] + tmp[tmp.length-1];
        }
	 }
|   < PHONE58 : (  ("+"|"&#43;")?(["0"-"9"]){1,2}< PSEP >  )?
		("(")?(["0"-"9"]){2,5}(")")?< PSEP >(["0"-"9"]){5,8}
	> { 
		tmp = image.toString().replaceAll(psep,"").split("[\\s,\\.,-]");
		if(tmp.length > 1) {
            matchedToken.image = tmp[tmp.length-2] + tmp[tmp.length-1];
        }
	 }
}

/*
	The following sections attempt to grab combined words/ tricky numbers.
	(Contractions, formatted numbers, or odd puntuation).

	It may pass through MORE once, or twice.
	Eventually, it's classified as WORD or NUMBER when it reaches the
	following regex expressions.

	I *may* use this to deal with w o r d s l i k e t h e s e.
*/

MORE :
	{
    < CONT : (["a"-"z","A"-"Z"])+ (< APS >|"-") > {
	  cont = true;
    }
| 	< BIGNUM : (["0"-"9"])+(","|"&#44;"|"."|"&#46;") >
}

/* Deal with situations where terms are too close to tags.*/

TOKEN : {
    < CROWDED : ">" ( (< CONT >)?(["a"-"z","A"-"Z"])+) > {
      	matchedToken.image = image.substring(image.indexOf(">")+1,image.length());
		matchedToken.image = matchedToken.image.replaceAll(aps,"");
		
    }
|   < CROWDED2 : ( (< CONT >)?(["a"-"z","A"-"Z"])+) < CLOSETAG > > {
  		matchedToken.image = image.substring(0,image.indexOf("<"));
		matchedToken.image = matchedToken.image.replaceAll(aps,"");
  		
    }
}

/* Misc. site specific entities. */

/* removed 6-13-19
TOKEN : {
    < REDDITU :  ["a"-"z"] (["/"]) (["a"-"z","A"-"Z","0"-"9"])+ > // Specifically for reddit, a popular platform. May need to revisit this.
|	< USER : ("@"|"&#64;") (["a"-"z","A"-"Z","0"-"9"])+ >
}*/
 
TOKEN : {
  	< WORD : (["a"-"z","A"-"Z"])+ > {

	  if(tagCt) {
  	    matchedToken.image = image.toString(); // If this word had odd punctuation, return the modfied image.
		tagCt = false;
	  }

	  if(cont) {
	    matchedToken.image = image.toString().replaceAll(aps,"");
		cont=false;
	  }
	  
  	}
|  	< BREV : (["A"-"Z"]("."|"&#46;")(" ")?)+ > {
  		matchedToken.image = matchedToken.image.replaceAll("\\.","").trim();
  	}
|   < TECH : ((["a"-"z","A"-"Z"])+(["0"-"9"])*){2,6} >
}

SKIP : {
   	< NUMBER : (["0"-"9"])+>
| 	< MISC: ~[] >
}

/*
	Skip parts of the url that may contribute more garbage than relevant information.
	(I am 60% certain that this information isn't useful).
*/

SKIP : {
 	< HTTPJNK : ("&"|"?"|"%") (["a"-"z","A"-"Z","0"-"9",".","-","_","=",";",":","+"])+ >
| 	< HTTPLNK : "/" (["a"-"z","A"-"Z","0"-"9",".","-","_","=",";",":","+"])+ >
|   < FILE : "./" (["a"-"z","A"-"Z","0"-"9",".","-","_","=",";",":","+"," "])+ >
|   < HTTP : ((["a"-"z"])+|("chrome-extension")) ("://")+ >
| 	< PORT : ":"(["0"-"9"]){2,4} >
}

/*
	Only retain HTML domains, parts of the url, email addresses that seem useful.
*/

TOKEN : {	
    < HTTPDOM : ( (["a"-"z","A"-"Z"]){1}(["a"-"z","A"-"Z"])+(".") )+ (["a"-"z","A"-"Z"])+ > {
        
        tmp = image.toString().split("\\.");
        matchedToken.image = tmp[tmp.length-2]+"."+tmp[tmp.length-1];
        
    }
|   < EMAIL : (["a"-"z","A"-"Z","0"-"9","_",".","+","-","=","#","$","%","&","!","*","?"])+ "@" ((["a"-"z","A"-"Z"])+(".")?)+ > // Fix, because it can't start or end with certain things?
}

/*-------------------------------*/
/* Tried, but unhelpful. Yet, I can't delete them.

|   < PRICE1 : ["$","£","¥"](["0"-"9"]){1,3}(","|".") > : PRICE_STATE

< PRICE_STATE > MORE :
{
	< PRICE2 : (["0"-"9"]){1,3}(","|".") >
}

< PRICE_STATE > TOKEN :
{
 	< PRICE : (["0"-"9"])+ > : DEFAULT
| 	< MISC2: ~[] > : DEFAULT 
}


|   < FLAG : (["a"-"z","A"-"Z"])+ ["<","/",">"] > { image.deleteCharAt(image.length()-1); System.out.println(image); } // Need to figure this out.


 ( (" ")*((["a"-"z","A"-"Z","0"-"9","-","=",";","[","]","_"])+(" ")*)+ )? "\""


  	< CROWDED2 :  (["a"-"z","A"-"Z","0"-"9"])+ "<" (" ")* ("/")?
  	 > {

		System.out.println(image);

		if(!tagCt) {
	  		tagCt = true;
	  	}
		image.delete(image.indexOf("<"),image.length()); // Probably not efficient.
		wordEnd=image.length();
  		
  	}

|	< TECH : ((["a"-"z","A"-"Z"])+(["0"-"9"])*){1,24} > {

	  if(tagCt) {

	    image.delete(wordEnd,image.length()); // Probably not efficient.
		matchedToken.image = image.toString(); // If this word had odd punctuation, set the modfied image.

		tagCt = false;
		
	  }
	  
	}

	image.delete(wordEnd,image.length()); // Probably not efficient.

	Need to address this case
	<h2>Keyboard Shortcuts</h2>
	<p> Keyboard 

	MORE :
	{
   	< OBS : (["a"-"z","A"-"Z"])+ (["<"]) > 
  	{
	  System.out.println(image);
  	  
	  if(!tagCt) {
	  	tagCt = true;
	  }
  	  tagSt = image.length()-1;

  	} : OBS_PARSE
|   < CONT : (["a"-"z","A"-"Z"])+"'" >
|   < TECH : (["a"-"z","A"-"Z"])+(["0"-"9"])+ >
| 	< BIGNUM : (["0"-"9"])+(","|".") >
}

	< OBS_PARSE > MORE : {
	< A : (">") > {
      image.delete(tagSt,image.length()); // Create a truncated word, without offending punctuation.
	  } : DEFAULT
| 	< C : ~[] > 
}
	
-------------------------------*/
